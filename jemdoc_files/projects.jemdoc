# jemdoc: menu{MENU}{projects.html}
= Projects
This page contains all my non-publication projects, including course 
projects, hackathons, personal projects and undergrad research.

== 2023


~~~
{}{img_left}{./images/rivian.jpg}{}{280px}{}{}{rivian}
== Rivian Adventure Retro Game
=== Asher Mai, Advaith Bala, David Chen
=== [https://github.com/uirphack/2023 2023 UIUC Research Park Hackathon]\n
=== /1st place and Best Company Incorporation Award/
Rivian Adventure is a retro game that incorporates many aspects of the company:
- Go offroad to activate camping mode and take advantage of Rivian's adventure focused trucks
- Go turbo mode and experience the fast acceleration of the R1T
- Drive through charging stations and don't worry about running out of battery
- When the truck breaks down, use Rivian Service Centers and you'll be back on the road in no time

[https://github.com/advaithbala/uirphack_2023 Code] \/ 
[https://youtu.be/4WL72N0womw Youtube] \/ 
[https://researchpark.illinois.edu/article/first-research-park-hackathon-paid-homage-to-retro-games/ Article]
~~~

~~~
{}{raw}
<script>
    $(function() {
        $("#rivian").hover(
            function() {
                $(this).attr("src", "./images/rivian.gif");
            },
            function() {
                $(this).attr("src", "./images/rivian.jpg");
            }                         
        );                  
    });
</script>
~~~

~~~
{}{img_left}{./images/head_controlled_mouse.gif}{}{280px}{}{}
== Head-Controlled Mouse
=== Amanda Favila, Asher Mai, Lauren Wilcox
=== ECE 445: Senior Design
We developed a device that allows a user with inability to move parts of their body to control
a mouse cursor using their head. We use an accelerometer and gyroscope to capture the movement
of the head, and translate it into mouse movement data that is sent by Bluetooth to the user's
desktop / laptop device. To left click or right click, simply hold the cursor in the place you
want to click, wait for the mouse to change into a crosshair shape, then tilt your head left or
right to perform left or right clicks.

[https://gitlab.com/ece445-team44/ece445_project Code] \/ 
[https://www.youtube.com/watch?v=HxvXf0QYEtk Youtube] \/ 
[./assets/ECE445_Final_Report.pdf Final Report] \/ 
[./assets/Team44_FinalPPT.pdf Presentation]
~~~


== 2022
~~~
{}{img_left}{./images/digital_notes.jpg}{}{280px}{}{}
== Digital Notes With Any Pen on Any Surface
=== Asher Mai, Pauline Lu
=== CS 445: Computational Photography
=== /[https://ece.illinois.edu/academics/ugrad/scholarships-and-awards/awards/bit Donald L. Bitzer and H. Gene Slottow Creativity Award]/
What if you want to draw or take notes digitally, but you don't have the money to buy an expensive set of tablet and stylus?
We designed a system that allows you to use any pen to draw on any surface using just your laptop's webcam.
First we do calibration to account for the angle of the webcam with relations to the surface in front of it using a piece 
of paper with green tapes on the four corners. We then use color thresholding to recognize the
green tip of the pen and its location on the surface, and translate it to location on screen using homography transform.

[https://gitlab.engr.illinois.edu/hanlinm2/digital-notes Code] \/ [https://www.youtube.com/watch?v=yeBxkBcJyF4 Youtube] \/ [./assets/CS445_Final_Project_Report.pdf Final Report]
~~~


~~~
{}{img_left}{./images/gesture.png}{}{280px}{}{}
== Hand Tracking and Gesture Recognition for Automated VFX
=== Michelle Zhang, Asher Mai, Noah Franceschini, Aditi Tiwari
=== CS 543/ECE 549: Computer Vision
We compared two different methods for the gesture detection problem: classical method with convex hull, and learning based
method with MobileNetV3. We applied different visual effects based on the gestures detected:
- One finger: A flame will show up on your finger and tilt based on hand movement determined by optical flow
- Two fingers: A flame will show up between the two fingers. Up and down motion will change the color of the flame
- Three fingers: Toggle on/off a cartoon filter.

[https://github.com/mz32-personal/ECE549-Final-Project Code] \/ [https://www.youtube.com/watch?v=c_B_kCH9-h4 Youtube] \/ [./assets/ECE549_Final_Report.pdf Final Report]
~~~

~~~
{}{img_left}{./images/yoyo.gif}{}{280px}{}{}
== Automatic Visual Effect on Yoyo Trick Videos 
=== Asher Mai
=== Personal Project
I taught myself how to do cool yoyo tricks. I taught myself how to program in Python. And I combined these
two skills to add automatic visual effects to my yoyo videos. I used OpenCV CSRT object tracker to track
the position of the yoyo in each frame, and then add a trace of the path that the yoyo takes.

[https://github.com/hanlinm2/yoyo_tracking_vfx Code]
~~~
